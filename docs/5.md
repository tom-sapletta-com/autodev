
# Plan Implementacji Systemu Autonomicznego

## 1. Konfiguracja Początkowa (System Minimalny)

### 1.1. Komponenty Bazowe
- **Docker Compose** - podstawowy plik do uruchomienia minimalnego zestawu usług
- **Rocket.Chat** - podstawowy system komunikacji
- **Ollama** - lokalny model LLM
- **Warstwa autonomiczna** - podstawowy system podejmowania decyzji

### 1.2. Plik Docker Compose dla konfiguracji początkowej

```yaml
version: '3.8'

services:
  # Ollama - lokalny model LLM
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped

  # MongoDB - baza dla Rocket.Chat
  mongo:
    image: mongo:5.0
    container_name: mongo
    volumes:
      - mongo_data:/data/db
    command: mongod --oplogSize 128
    restart: unless-stopped

  # Rocket.Chat - system komunikacji
  rocketchat:
    image: rocketchat/rocket.chat:latest
    container_name: rocketchat
    ports:
      - "3000:3000"
    environment:
      - PORT=3000
      - ROOT_URL=http://localhost:3000
      - MONGO_URL=mongodb://mongo:27017/rocketchat
      - MONGO_OPLOG_URL=mongodb://mongo:27017/local
      - ADMIN_USERNAME=admin
      - ADMIN_PASS=password
      - ADMIN_EMAIL=admin@example.com
    depends_on:
      - mongo
    restart: unless-stopped

  # Middleware API - komunikacja między usługami
  middleware-api:
    build:
      context: ./middleware-api
      dockerfile: Dockerfile
    container_name: middleware-api
    ports:
      - "5000:5000"
    volumes:
      - ./middleware-api:/app
    environment:
      - OLLAMA_API_URL=http://ollama:11434
      - ROCKETCHAT_URL=http://rocketchat:3000
    depends_on:
      - ollama
      - rocketchat
    restart: unless-stopped

volumes:
  ollama_data:
  mongo_data:
```

### 1.3. Struktura Folderu Początkowego

```
.
├── docker-compose.yml           # Plik konfiguracyjny Docker Compose
├── middleware-api/              # Warstwa pośrednia komunikująca komponenty
│   ├── Dockerfile               # Definicja obrazu Docker
│   ├── app.py                   # Główna aplikacja Flask/FastAPI
│   ├── autonomous_layer.py      # Warstwa autonomiczna
│   ├── docker_manager.py        # Zarządzanie usługami Docker
│   ├── ollama_client.py         # Klient API Ollama
│   └── rocketchat_client.py     # Klient API Rocket.Chat
├── data/                        # Folder na dane systemu
└── scripts/                     # Skrypty pomocnicze
    ├── setup.sh                 # Skrypt inicjalizacyjny
    └── backup.sh                # Skrypt tworzenia kopii zapasowych
```

## 2. Implementacja modułu middleware-api (kluczowy komponent)

### 2.1. Główna aplikacja API (app.py)

```python
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
import uvicorn
import logging
from typing import List, Dict, Any

from autonomous_layer import AutonomousLayer
from ollama_client import OllamaClient
from rocketchat_client import RocketChatClient
from docker_manager import DockerManager

# Konfiguracja logowania
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("system.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI(title="System Autonomiczny API")

# Inicjalizacja klientów
ollama_client = OllamaClient()
rocketchat_client = RocketChatClient()
docker_manager = DockerManager()
autonomous_layer = AutonomousLayer(ollama_client, rocketchat_client, docker_manager)

# Modele danych
class Message(BaseModel):
    user_id: str
    text: str
    room_id: str

class Task(BaseModel):
    title: str
    description: str
    priority: int = 1
    tags: List[str] = []
    user_id: str

class ServiceRequest(BaseModel):
    service_type: str
    description: str
    reason: str

# Endpointy API
@app.get("/")
def read_root():
    return {"status": "Online", "system": "Autonomiczny System"}

@app.get("/status")
def get_status():
    status = {
        "ollama": ollama_client.get_status(),
        "rocketchat": rocketchat_client.get_status(),
        "docker": docker_manager.get_status(),
        "services": docker_manager.list_services()
    }
    return status

@app.post("/message")
async def process_message(message: Message, background_tasks: BackgroundTasks):
    """Przetwarzanie wiadomości z Rocket.Chat"""
    logger.info(f"Otrzymano wiadomość: {message.text}")
    
    # Rozpoczęcie przetwarzania w tle
    background_tasks.add_task(
        autonomous_layer.process_message,
        message.user_id,
        message.text,
        message.room_id
    )
    
    return {"status": "accepted", "message": "Wiadomość została przyjęta do przetworzenia"}

@app.post("/task")
async def create_task(task: Task, background_tasks: BackgroundTasks):
    """Utworzenie nowego zadania"""
    logger.info(f"Utworzono zadanie: {task.title}")
    
    # Rozpoczęcie przetwarzania zadania w tle
    background_tasks.add_task(
        autonomous_layer.process_task,
        task.dict()
    )
    
    return {"status": "created", "task_id": "task_123"}  # W rzeczywistej implementacji ID zadania byłoby generowane

@app.post("/service")
async def add_service(service: ServiceRequest):
    """Dodanie nowej usługi Docker"""
    logger.info(f"Prośba o dodanie usługi: {service.service_type}")
    
    result = docker_manager.add_service(
        service.service_type,
        service.description,
        service.reason
    )
    
    if result.get("success", False):
        return {"status": "success", "service_id": result.get("service_id")}
    else:
        raise HTTPException(status_code=400, detail=result.get("error", "Unknown error"))

@app.get("/services")
def list_services():
    """Listowanie dostępnych usług Docker"""
    services = docker_manager.list_services()
    return {"services": services}

@app.get("/capabilities")
def get_capabilities():
    """Pobranie aktualnych możliwości systemu"""
    capabilities = autonomous_layer.get_capabilities()
    return {"capabilities": capabilities}

@app.post("/evolve")
async def evolve_system(background_tasks: BackgroundTasks):
    """Zainicjowanie procesu ewolucji systemu"""
    logger.info("Rozpoczęcie procesu ewolucji systemu")
    
    background_tasks.add_task(autonomous_layer.evolve_system)
    
    return {"status": "started", "message": "Rozpoczęto proces ewolucji systemu"}

if __name__ == "__main__":
    uvicorn.run("app:app", host="0.0.0.0", port=5000, reload=True)
```

### 2.2. Warstwa autonomiczna (autonomous_layer.py)

```python
import logging
import time
import threading
import asyncio
from typing import Dict, List, Any

logger = logging.getLogger(__name__)

class AutonomousLayer:
    """Centralna warstwa autonomiczna systemu"""
    
    def __init__(self, ollama_client, rocketchat_client, docker_manager):
        self.ollama_client = ollama_client
        self.rocketchat_client = rocketchat_client
        self.docker_manager = docker_manager
        self.capabilities = self._init_capabilities()
        self.evolution_level = 0
        self.lock = threading.Lock()
        
    def _init_capabilities(self) -> Dict[str, bool]:
        """Inicjalizacja bazowych możliwości systemu"""
        return {
            "chat": True,
            "voice": False,
            "code_generation": False,
            "data_analysis": False,
            "visualization": False,
            "version_control": False,
            "ci_cd": False,
            "advanced_automation": False
        }
        
    def get_capabilities(self) -> Dict[str, bool]:
        """Pobranie aktualnych możliwości systemu"""
        return self.capabilities
        
    async def process_message(self, user_id: str, text: str, room_id: str):
        """Przetwarzanie wiadomości od użytkownika"""
        logger.info(f"Przetwarzanie wiadomości od {user_id}: {text}")
        
        # Analiza wiadomości przez Ollama
        response = self.ollama_client.generate(
            prompt=f"User message: {text}\nYour task: Analyze this message and determine if it requires any system evolution or new capabilities.",
            model="llama3:7b"
        )
        
        # Sprawdzenie, czy wiadomość wymaga ewolucji systemu
        needs_evolution = self._check_evolution_needs(response, text)
        
        if needs_evolution:
            # Powiadomienie użytkownika o potrzebie ewolucji
            await self._notify_evolution_needed(user_id, room_id, needs_evolution)
        else:
            # Standardowa odpowiedź
            reply = self.ollama_client.generate(
                prompt=f"User message: {text}\nYour task: Respond to this message as a helpful assistant.",
                model="llama3:7b"
            )
            
            # Wysłanie odpowiedzi
            self.rocketchat_client.send_message(room_id, reply)
        
    def _check_evolution_needs(self, analysis: str, original_message: str) -> Dict:
        """Sprawdzenie, czy wiadomość sugeruje potrzebę ewolucji systemu"""
        # To jest uproszczona implementacja - w rzeczywistym systemie byłaby bardziej zaawansowana
        evolution_keywords = {
            "voice": ["głos", "mówić", "rozmawiać głosowo", "audio"],
            "code": ["kod", "programowanie", "aplikacja", "stworzyć program"],
            "data": ["dane", "analiza", "wykres", "statystyki", "csv", "excel"],
            "version_control": ["git", "wersja", "gitlab", "kontrola wersji"],
            "ci_cd": ["ci/cd", "continuous integration", "wdrożenie", "pipeline"]
        }
        
        needed_capabilities = {}
        
        for capability, keywords in evolution_keywords.items():
            if any(keyword in original_message.lower() for keyword in keywords):
                if not self.capabilities.get(capability, False):
                    needed_capabilities[capability] = True
                    
        return needed_capabilities
        
    async def _notify_evolution_needed(self, user_id: str, room_id: str, needed_capabilities: Dict[str, bool]):
        """Powiadomienie użytkownika o potrzebie ewolucji systemu"""
        capability_names = {
            "voice": "obsługa głosu (rozpoznawanie i synteza mowy)",
            "code": "środowisko programistyczne (generowanie i wykonywanie kodu)",
            "data": "analiza danych i wizualizacja",
            "version_control": "system kontroli wersji (GitLab)",
            "ci_cd": "automatyczne wdrażanie (CI/CD Pipeline)"
        }
        
        capabilities_text = ", ".join([capability_names[cap] for cap in needed_capabilities.keys()])
        
        message = f"""
Wykryłem, że do realizacji Twojego żądania potrzebuję dodatkowych możliwości, których obecnie nie posiadam.

Potrzebne możliwości: {capabilities_text}

Czy chcesz, abym zainstalował i skonfigurował te komponenty, aby móc lepiej Ci pomóc?
        """
        
        self.rocketchat_client.send_message(room_id, message)
        
    async def process_task(self, task: Dict):
        """Przetwarzanie zadania"""
        logger.info(f"Przetwarzanie zadania: {task['title']}")
        
        # Implementacja przetwarzania zadania
        # ...
        
    async def evolve_system(self):
        """Ewolucja systemu do kolejnego poziomu"""
        with self.lock:  # Zapobieganie jednoczesnym ewolucjom
            current_level = self.evolution_level
            next_level = current_level + 1
            
            logger.info(f"Rozpoczęcie ewolucji systemu z poziomu {current_level} do {next_level}")
            
            # Implementacja ewolucji zależna od poziomu
            if next_level == 1:
                await self._evolve_to_level_1()
            elif next_level == 2:
                await self._evolve_to_level_2()
            elif next_level == 3:
                await self._evolve_to_level_3()
            elif next_level == 4:
                await self._evolve_to_level_4()
            else:
                logger.warning(f"Nieznany poziom ewolucji: {next_level}")
                return
                
            # Aktualizacja poziomu ewolucji
            self.evolution_level = next_level
            logger.info(f"Zakończono ewolucję do poziomu {next_level}")
            
    async def _evolve_to_level_1(self):
        """Ewolucja do poziomu 1: Komunikacja rozszerzona"""
        logger.info("Ewolucja do poziomu 1: Dodawanie obsługi głosu")
        
        # Dodanie usług STT/TTS
        self.docker_manager.add_service(
            "stt",
            "Usługa rozpoznawania mowy (Vosk)",
            "Potrzebna do obsługi komunikacji głosowej"
        )
        
        self.docker_manager.add_service(
            "tts",
            "Usługa syntezy mowy (Mozilla TTS)",
            "Potrzebna do obsługi komunikacji głosowej"
        )
        
        # Aktualizacja możliwości
        self.capabilities["voice"] = True
        
        # Powiadomienie o zakończeniu ewolucji
        # ...
        
    async def _evolve_to_level_2(self):
        """Ewolucja do poziomu 2: Środowisko programistyczne"""
        logger.info("Ewolucja do poziomu 2: Dodawanie środowiska programistycznego")
        
        # Dodanie VS Code Server
        self.docker_manager.add_service(
            "code-server",
            "VS Code Server z rozszerzeniami",
            "Środowisko programistyczne do generowania i wykonywania kodu"
        )
        
        # Dodanie GitLab
        self.docker_manager.add_service(
            "gitlab",
            "GitLab CE (system kontroli wersji)",
            "System kontroli wersji do zarządzania kodem"
        )
        
        # Aktualizacja możliwości
        self.capabilities["code_generation"] = True
        self.capabilities["version_control"] = True
        
        # Powiadomienie o zakończeniu ewolucji
        # ...
        
    async def _evolve_to_level_3(self):
        """Ewolucja do poziomu 3: Zaawansowana automatyzacja"""
        logger.info("Ewolucja do poziomu 3: Dodawanie zaawansowanej automatyzacji")
        
        # Dodanie serwera CI/CD
        self.docker_manager.add_service(
            "gitlab-runner",
            "GitLab Runner (CI/CD)",
            "Runner dla zadań CI/CD w GitLab"
        )
        
        # Dodanie narzędzi do analizy danych
        self.docker_manager.add_service(
            "jupyter",
            "Jupyter Notebook Server",
            "Środowisko do analizy danych i wizualizacji"
        )
        
        # Dodanie bazy danych
        self.docker_manager.add_service(
            "postgres",
            "PostgreSQL Database",
            "Baza danych do przechowywania danych projektów"
        )
        
        # Aktualizacja możliwości
        self.capabilities["ci_cd"] = True
        self.capabilities["data_analysis"] = True
        self.capabilities["visualization"] = True
        
        # Powiadomienie o zakończeniu ewolucji
        # ...
        
    async def _evolve_to_level_4(self):
        """Ewolucja do poziomu 4: Pełna autonomia"""
        logger.info("Ewolucja do poziomu 4: Dodawanie pełnej autonomii")
        
        # Dodanie menedżera zasobów
        self.docker_manager.add_service(
            "resource-manager",
            "Menedżer zasobów systemu",
            "Automatyczne zarządzanie zasobami sprzętowymi"
        )
        
        # Dodanie systemu monitoringu
        self.docker_manager.add_service(
            "prometheus",
            "Prometheus Monitoring",
            "System monitorowania usług i zasobów"
        )
        
        self.docker_manager.add_service(
            "grafana",
            "Grafana Dashboard",
            "Wizualizacja metryk z Prometheus"
        )
        
        # Dodanie mechanizmu uczenia na podstawie interakcji
        self.docker_manager.add_service(
            "learning-system",
            "System uczenia się preferencji użytkownika",
            "Adaptacja systemu do wzorców użytkowania"
        )
        
        # Aktualizacja możliwości
        self.capabilities["advanced_automation"] = True
        
        # Powiadomienie o zakończeniu ewolucji
        # ...
```

### 2.3. Zarządzanie usługami Docker (docker_manager.py)

```python
import logging
import docker
import yaml
import os
import uuid
from typing import Dict, List, Any

logger = logging.getLogger(__name__)

class DockerManager:
    """Klasa do zarządzania usługami Docker w systemie autonomicznym"""
    
    def __init__(self, compose_file: str = "docker-compose.yml"):
        self.compose_file = compose_file
        self.client = docker.from_env()
        self.service_templates = self._load_service_templates()
        
    def _load_service_templates(self) -> Dict[str, Dict]:
        """Ładowanie szablonów usług Docker"""
        # W rzeczywistej implementacji szablony mogłyby być ładowane z pliku
        return {
            # Szablony usług komunikacyjnych
            "stt": {
                "image": "alphacep/kaldi-vosk-server:latest",
                "ports": ["2700:2700"],
                "volumes": ["./models:/opt/vosk-model"],
                "restart": "unless-stopped"
            },
            "tts": {
                "image": "synesthesiam/mozilla-tts:latest",
                "ports": ["5002:5002"],
                "restart": "unless-stopped"
            },
            
            # Szablony środowiska programistycznego
            "code-server": {
                "image": "linuxserver/code-server:latest",
                "ports": ["8443:8443"],
                "volumes": [
                    "./vscode-config:/config",
                    "./workspace:/config/workspace"
                ],
                "environment": {
                    "PUID": "1000",
                    "PGID": "1000",
                    "TZ": "Europe/Warsaw",
                    "PASSWORD": "password123"  # Powinno być zabezpieczone w produkcji
                },
                "restart": "unless-stopped"
            },
            "gitlab": {
                "image": "gitlab/gitlab-ce:latest",
                "ports": ["8080:80", "8022:22"],
                "volumes": [
                    "gitlab_config:/etc/gitlab",
                    "gitlab_logs:/var/log/gitlab",
                    "gitlab_data:/var/opt/gitlab"
                ],
                "environment": {
                    "GITLAB_OMNIBUS_CONFIG": (
                        "external_url 'http://localhost:8080'\n"
                        "gitlab_rails['gitlab_shell_ssh_port'] = 8022\n"
                    )
                },
                "restart": "unless-stopped"
            },
            
            # Szablony CI/CD
            "gitlab-runner": {
                "image": "gitlab/gitlab-runner:latest",
                "volumes": [
                    "/var/run/docker.sock:/var/run/docker.sock",
                    "gitlab_runner_config:/etc/gitlab-runner"
                ],
                "restart": "unless-stopped",
                "depends_on": ["gitlab"]
            },
            
            # Szablony analizy danych
            "jupyter": {
                "image": "jupyter/datascience-notebook:latest",
                "ports": ["8888:8888"],
                "volumes": ["./jupyter-notebooks:/home/jovyan/work"],
                "environment": {
                    "JUPYTER_ENABLE_LAB": "yes"
                },
                "restart": "unless-stopped"
            },
            "postgres": {
                "image": "postgres:14",
                "ports": ["5432:5432"],
                "volumes": ["postgres_data:/var/lib/postgresql/data"],
                "environment": {
                    "POSTGRES_PASSWORD": "postgres",
                    "POSTGRES_USER": "postgres",
                    "POSTGRES_DB": "default"
                },
                "restart": "unless-stopped"
            },
            
            # Szablony monitorowania
            "prometheus": {
                "image": "prom/prometheus:latest",
                "ports": ["9090:9090"],
                "volumes": ["./prometheus-config:/etc/prometheus"],
                "restart": "unless-stopped"
            },
            "grafana": {
                "image": "grafana/grafana:latest",
                "ports": ["3001:3000"],
                "volumes": ["grafana_data:/var/lib/grafana"],
                "restart": "unless-stopped",
                "depends_on": ["prometheus"]
            },
            
            # Inne szablony usług
            "learning-system": {
                "build": {
                    "context": "./learning-system",
                    "dockerfile": "Dockerfile"
                },
                "volumes": ["./learning-system:/app"],
                "restart": "unless-stopped"
            },
            "resource-manager": {
                "build": {
                    "context": "./resource-manager",
                    "dockerfile": "Dockerfile"
                },
                "volumes": [
                    "/var/run/docker.sock:/var/run/docker.sock",
                    "./resource-manager:/app"
                ],
                "restart": "unless-stopped"
            }
        }
        
    def load_compose_file(self) -> Dict:
        """Ładowanie istniejącego pliku docker-compose.yml"""
        if os.path.exists(self.compose_file):
            with open(self.compose_file, 'r') as f:
                return yaml.safe_load(f) or {"version": "3.8", "services": {}}
        else:
            return {"version": "3.8", "services": {}}
        
    def save_compose_file(self, compose_data: Dict):
        """Zapisanie danych do pliku docker-compose.yml"""
        with open(self.compose_file, 'w') as f:
            yaml.dump(compose_data, f, default_flow_style=False)
            
    def get_status(self) -> Dict:
        """Pobranie statusu menedżera Docker"""
        try:
            info = self.client.info()
            return {
                "status": "ok",
                "containers": len(self.client.containers.list()),
                "version": info.get("ServerVersion", "unknown")
            }
        except Exception as e:
            logger.error(f"Błąd podczas pobierania statusu Docker: {str(e)}")
            return {"status": "error", "error": str(e)}
        
    def list_services(self) -> List[Dict]:
        """Listowanie dostępnych usług Docker"""
        compose_data = self.load_compose_file()
        services = []
        
        for service_name, service_config in compose_data.get("services", {}).items():
            # Pobranie statusu usługi (czy działa)
            status = "unknown"
            try:
                containers = self.client.containers.list(
                    filters={"name": service_name}
                )
                if containers:
                    status = containers[0].status
            except Exception:
                pass
            
            services.append({
                "name": service_name,
                "image": service_config.get("image", "custom"),
                "status": status
            })
            
        return services
        
    def add_service(self, service_type: str, description: str, reason: str) -> Dict:
        """Dodanie nowej usługi Docker"""
        logger.info(f"Dodawanie usługi typu {service_type}: {description}")
        
        # Sprawdzenie czy szablon usługi istnieje
        if service_type not in self.service_templates:
            return {
                "success": False,
                "error": f"Nieznany typ usługi: {service_type}"
            }
            
        # Generowanie unikalnego ID dla usługi
        service_id = str(uuid.uuid4())[:8]
        service_name = f"{service_type}_{service_id}"
        
        # Ładowanie aktualnej konfiguracji
        compose_data = self.load_compose_file()
        
        # Sprawdzenie czy usługa już istnieje
        if service_name in compose_data.get("services", {}):
            return {
                "success": False,
                "error": f"Usługa o nazwie {service_name} już istnieje"
            }
            
        # Tworzenie konfiguracji usługi
        service_config = self.service_templates[service_type].copy()
        
        # Dodanie usługi do konfiguracji
        if "services" not in compose_data:
            compose_data["services"] = {}
            
        compose_data["services"][service_name] = service_config
        
        # Sprawdzenie, czy potrzebne są dodatkowe wolumeny
        volumes_in_service = self._extract_volumes_from_service(service_config)
        
        # Dodanie wolumenów do konfiguracji
        if volumes_in_service and "volumes" not in compose_data:
            compose_data["volumes"] = {}
            
        for volume in volumes_in_service:
            if volume not in compose_data.get("volumes", {}):
                compose_data["volumes"][volume] = {}
                
        # Zapisanie zmian
        self.save_compose_file(compose_data)
        
        # Próba uruchomienia usługi
        try:
            import subprocess
            result = subprocess.run(
                f"docker-compose -f {self.compose_file} up -d {service_name}",
                shell=True,
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                logger.error(f"Błąd podczas uruchamiania usługi: {result.stderr}")
                return {
                    "success": True,  # Usługa została dodana, ale nie uruchomiona
                    "service_id": service_name,
                    "warning": f"Usługa została dodana, ale wystąpił błąd podczas uruchamiania: {result.stderr}"
                }
        except Exception as e:
            logger.error(f"Wyjątek podczas uruchamiania usługi: {str(e)}")
            return {
                "success": True,  # Usługa została dodana, ale nie uruchomiona
                "service_id": service_name,
                "warning": f"Usługa została dodana, ale wystąpił błąd podczas uruchamiania: {str(e)}"
            }
            
        return {
            "success": True,
            "service_id": service_name,
            "message": f"Usługa {service_name} została dodana i uruchomiona"
        }
        
    def _extract_volumes_from_service(self, service_config: Dict) -> List[str]:
        """Wyodrębnienie nazw wolumenów z konfiguracji usługi"""
        volumes = []
        
        if "volumes" in service_config:
            for volume in service_config["volumes"]:
                # Sprawdzenie czy to jest zapis wolumenu nazwowego (nie ścieżka)
                if ":" in volume and not volume.startswith("./") and not volume.startswith("/"):
                    volume_name = volume.split(":")[0]
                    volumes.append(volume_name)
                    
        return volumes
        
    def remove_service(self, service_name: str) -> Dict:
        """Usunięcie usługi Docker"""
        logger.info(f"Usuwanie usługi {service_name}")
        
        # Ładowanie aktualnej konfiguracji
        compose_data = self.load_compose_file()
        
        # Sprawdzenie czy usługa istnieje
        if service_name not in compose_data.get("services", {}):
            return {
                "success": False,
                "error": f"Usługa o nazwie {service_name} nie istnieje"
            }
            
        # Zatrzymanie i usunięcie kontenerów
        try:
            import subprocess
            result = subprocess.run(
                f"docker-compose -f {self.compose_file} rm -sf {service_name}",
                shell=True,
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                logger.error(f"Błąd podczas usuwania kontenerów: {result.stderr}")
        except Exception as e:
            logger.error(f"Wyjątek podczas usuwania kontenerów: {str(e)}")
            
        # Usunięcie usługi z konfiguracji
        del compose_data["services"][service_name]
        
        # Zapisanie zmian
        self.save_compose_file(compose_data)
        
        return {
            "success": True,
            "message": f"Usługa {service_name} została usunięta"
        }
```

### 2.4. Klient Ollama (ollama_client.py)

```python
import requests
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

class OllamaClient:
    """Klient API dla modelu Ollama"""
    
    def __init__(self, base_url: str = "http://ollama:11434"):
        self.base_url = base_url
        
    def get_status(self) -> Dict:
        """Sprawdzenie statusu Ollama"""
        try:
            response = requests.get(f"{self.base_url}/api/tags")
            if response.status_code == 200:
                return {"status": "ok", "models": len(response.json().get("models", []))}
            else:
                return {"status": "error", "error": f"HTTP {response.status_code}"}
        except Exception as e:
            logger.error(f"Błąd podczas sprawdzania statusu Ollama: {str(e)}")
            return {"status": "error", "error": str(e)}
            
    def generate(self, prompt: str, model: str = "llama3:7b", system: Optional[str] = None) -> str:
        """Generowanie tekstu przez model Ollama"""
        try:
            data = {
                "model": model,
                "prompt": prompt,
                "stream": False
            }
            
            if system:
                data["system"] = system
                
            response = requests.post(
                f"{self.base_url}/api/generate",
                json=data
            )
            
            if response.status_code == 200:
                return response.json().get("response", "")
            else:
                logger.error(f"Błąd odpowiedzi Ollama: {response.text}")
                return f"Error: {response.status_code}"
                
        except Exception as e:
            logger.error(f"Wyjątek podczas generowania tekstu: {str(e)}")
            return f"Error: {str(e)}"
            
    def chat(self, messages: list, model: str = "llama3:7b") -> str:
        """Wywołanie API czatu Ollama"""
        try:
            data = {
                "model": model,
                "messages": messages,
                "stream": False
            }
            
            response = requests.post(
                f"{self.base_url}/api/chat",
                json=data
            )
            
            if response.status_code == 200:
                return response.json().get("message", {}).get("content", "")
            else:
                logger.error(f"Błąd odpowiedzi Ollama: {response.text}")
                return f"Error: {response.status_code}"
                
        except Exception as e:
            logger.error(f"Wyjątek podczas wywołania czatu: {str(e)}")
            return f"Error: {str(e)}"
            
    def list_models(self) -> list:
        """Pobranie listy dostępnych modeli"""
        try:
            response = requests.get(f"{self.base_url}/api/tags")
            
            if response.status_code == 200:
                return response.json().get("models", [])
            else:
                logger.error(f"Błąd odpowiedzi Ollama: {response.text}")
                return []
                
        except Exception as e:
            logger.error(f"Wyjątek podczas listowania modeli: {str(e)}")
            return []
            
    def pull_model(self, model_name: str) -> bool:
        """Pobranie modelu przez Ollama"""
        try:
            data = {
                "name": model_name
            }
            
            response = requests.post(
                f"{self.base_url}/api/pull",
                json=data
            )
            
            return response.status_code == 200
            
        except Exception as e:
            logger.error(f"Wyjątek podczas pobierania modelu: {str(e)}")
            return False
```

### 2.5. Klient Rocket.Chat (rocketchat_client.py)

```python
import requests
import logging
from typing import Dict, Any, List, Optional

logger = logging.getLogger(__name__)

class RocketChatClient:
    """Klient API dla Rocket.Chat"""
    
    def __init__(self, base_url: str = "http://rocketchat:3000", 
                 username: str = "admin", password: str = "password"):
        self.base_url = base_url
        self.username = username
        self.password = password
        self.auth_token = None
        self.user_id = None
        
    def get_status(self) -> Dict:
        """Sprawdzenie statusu Rocket.Chat"""
        try:
            response = requests.get(f"{self.base_url}/api/info")
            if response.status_code == 200:
                return {"status": "ok", "version": response.json().get("version", "unknown")}
            else:
                return {"status": "error", "error": f"HTTP {response.status_code}"}
        except Exception as e:
            logger.error(f"Błąd podczas sprawdzania statusu Rocket.Chat: {str(e)}")
            return {"status": "error", "error": str(e)}
            
    def login(self) -> bool:
        """Logowanie do Rocket.Chat"""
        if self.auth_token and self.user_id:
            return True
            
        try:
            response = requests.post(
                f"{self.base_url}/api/v1/login",
                json={
                    "username": self.username,
                    "password": self.password
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                if data.get("status") == "success":
                    self.auth_token = data.get("data", {}).get("authToken")
                    self.user_id = data.get("data", {}).get("userId")
                    return True
                    
            logger.error(f"Błąd logowania do Rocket.Chat: {response.text}")
            return False
            
        except Exception as e:
            logger.error(f"Wyjątek podczas logowania do Rocket.Chat: {str(e)}")
            return False
            
    def get_headers(self) -> Dict:
        """Pobranie nagłówków autoryzacyjnych"""
        if not self.auth_token or not self.user_id:
            if not self.login():
                return {}
                
        return {
            "X-Auth-Token": self.auth_token,
            "X-User-Id": self.user_id,
            "Content-Type": "application/json"
        }
        
    def send_message(self, room_id: str, text: str) -> bool:
        """Wysłanie wiadomości na kanał"""
        headers = self.get_headers()
        if not headers:
            return False
            
        try:
            response = requests.post(
                f"{self.base_url}/api/v1/chat.postMessage",
                headers=headers,
                json={
                    "roomId": room_id,
                    "text": text
                }
            )
            
            return response.status_code == 200
            
        except Exception as e:
            logger.error(f"Wyjątek podczas wysyłania wiadomości: {str(e)}")
            return False
            
    def create_channel(self, name: str, members: Optional[List[str]] = None, 
                      private: bool = False) -> Dict:
        """Utworzenie nowego kanału"""
        headers = self.get_headers()
        if not headers:
            return {"success": False, "error": "Not authenticated"}
            
        try:
            url = f"{self.base_url}/api/v1/{'groups' if private else 'channels'}.create"
            
            data = {
                "name": name
            }
            
            if members:
                data["members"] = members
                
            response = requests.post(
                url,
                headers=headers,
                json=data
            )
            
            if response.status_code == 200:
                return {"success": True, "data": response.json()}
            else:
                return {"success": False, "error": response.text}
                
        except Exception as e:
            logger.error(f"Wyjątek podczas tworzenia kanału: {str(e)}")
            return {"success": False, "error": str(e)}
            
    def get_channel_id(self, channel_name: str) -> Optional[str]:
        """Pobranie ID kanału na podstawie nazwy"""
        headers = self.get_headers()
        if not headers:
            return None
            
        try:
            # Próba pobrania publicznego kanału
            response = requests.get(
                f"{self.base_url}/api/v1/channels.info?roomName={channel_name}",
                headers=headers
            )
            
            if response.status_code == 200:
                return response.json().get("channel", {}).get("_id")
                
            # Próba pobrania prywatnego kanału
            response = requests.get(
                f"{self.base_url}/api/v1/groups.info?roomName={channel_name}",
                headers=headers
            )
            
            if response.status_code == 200:
                return response.json().get("group", {}).get("_id")
                
            return None
            
        except Exception as e:
            logger.error(f"Wyjątek podczas pobierania ID kanału: {str(e)}")
            return None
```

## 3. Dockerfile dla middleware-api

```dockerfile
FROM python:3.9-slim

WORKDIR /app

# Instalacja zależności systemowych
RUN apt-get update && apt-get install -y \
    git \
    curl \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Kopiowanie plików wymagań
COPY requirements.txt .

# Instalacja zależności Pythona
RUN pip install --no-cache-dir -r requirements.txt

# Kopiowanie kodu aplikacji
COPY . .

# Nadanie uprawnień wykonawczych dla skryptów
RUN chmod +x /app/scripts/*.sh

# Ustawienie zmiennych środowiskowych
ENV PYTHONUNBUFFERED=1

# Ekspozycja portu
EXPOSE 5000

# Uruchomienie aplikacji
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "5000"]
```

## 4. Plik requirements.txt dla middleware-api

```
fastapi>=0.68.0
uvicorn>=0.15.0
docker>=5.0.0
pyyaml>=6.0
requests>=2.26.0
python-dotenv>=0.19.0
pydantic>=1.8.2
websockets>=10.0
pytz>=2021.3
aiohttp>=3.8.0
```

## 5. Skrypt inicjalizacyjny (setup.sh)

```bash
#!/bin/bash

# Skrypt inicjalizacyjny dla systemu autonomicznego

# Kolory dla lepszej czytelności
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
NC='\033[0m' # No Color

# Banner
echo -e "${GREEN}"
echo "=================================="
echo " System Autonomiczny - Inicjalizacja"
echo "=================================="
echo -e "${NC}"

# Sprawdzenie wymagań
echo -e "${YELLOW}Sprawdzanie wymagań...${NC}"

# Docker
if ! command -v docker &> /dev/null; then
    echo -e "${RED}Docker nie jest zainstalowany. Proszę zainstalować Docker przed kontynuacją.${NC}"
    exit 1
fi

# Docker Compose
if ! command -v docker-compose &> /dev/null; then
    echo -e "${RED}Docker Compose nie jest zainstalowany. Proszę zainstalować Docker Compose przed kontynuacją.${NC}"
    exit 1
fi

echo -e "${GREEN}Wszystkie wymagania spełnione.${NC}"

# Tworzenie struktury katalogów
echo -e "${YELLOW}Tworzenie struktury katalogów...${NC}"

mkdir -p data/ollama
mkdir -p data/mongo
mkdir -p middleware-api
mkdir -p scripts

echo -e "${GREEN}Struktura katalogów utworzona.${NC}"

# Tworzenie pliku docker-compose.yml
echo -e "${YELLOW}Tworzenie pliku docker-compose.yml...${NC}"

cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  # Ollama - lokalny model LLM
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped

  # MongoDB - baza dla Rocket.Chat
  mongo:
    image: mongo:5.0
    container_name: mongo
    volumes:
      - mongo_data:/data/db
    command: mongod --oplogSize 128
    restart: unless-stopped

  # Rocket.Chat - system komunikacji
  rocketchat:
    image: rocketchat/rocket.chat:latest
    container_name: rocketchat
    ports:
      - "3000:3000"
    environment:
      - PORT=3000
      - ROOT_URL=http://localhost:3000
      - MONGO_URL=mongodb://mongo:27017/rocketchat
      - MONGO_OPLOG_URL=mongodb://mongo:27017/local
      - ADMIN_USERNAME=admin
      - ADMIN_PASS=password
      - ADMIN_EMAIL=admin@example.com
    depends_on:
      - mongo
    restart: unless-stopped

  # Middleware API - komunikacja między usługami
  middleware-api:
    build:
      context: ./middleware-api
      dockerfile: Dockerfile
    container_name: middleware-api
    ports:
      - "5000:5000"
    volumes:
      - ./middleware-api:/app
    environment:
      - OLLAMA_API_URL=http://ollama:11434
      - ROCKETCHAT_URL=http://rocketchat:3000
    depends_on:
      - ollama
      - rocketchat
    restart: unless-stopped

volumes:
  ollama_data:
  mongo_data:
EOF

echo -e "${GREEN}Plik docker-compose.yml utworzony.${NC}"

# Tworzenie plików middleware-api
echo -e "${YELLOW}Tworzenie plików middleware-api...${NC}"

# Tworzenie pliku requirements.txt
cat > middleware-api/requirements.txt << 'EOF'
fastapi>=0.68.0
uvicorn>=0.15.0
docker>=5.0.0
pyyaml>=6.0
requests>=2.26.0
python-dotenv>=0.19.0
pydantic>=1.8.2
websockets>=10.0
pytz>=2021.3
aiohttp>=3.8.0
EOF

# Tworzenie pliku Dockerfile
cat > middleware-api/Dockerfile << 'EOF'
FROM python:3.9-slim

WORKDIR /app

# Instalacja zależności systemowych
RUN apt-get update && apt-get install -y \
    git \
    curl \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Kopiowanie plików wymagań
COPY requirements.txt .

# Instalacja zależności Pythona
RUN pip install --no-cache-dir -r requirements.txt

# Kopiowanie kodu aplikacji
COPY . .

# Nadanie uprawnień wykonawczych dla skryptów
RUN chmod +x /app/scripts/*.sh 2>/# Plan Implementacji Systemu Autonomicznego

## 1. Konfiguracja Początkowa (System Minimalny)

### 1.1. Komponenty Bazowe
- **Docker Compose** - podstawowy plik do uruchomienia minimalnego zestawu usług
- **Rocket.Chat** - podstawowy system komunikacji
- **Ollama** - lokalny model LLM
- **Warstwa autonomiczna** - podstawowy system podejmowania decyzji

### 1.2. Plik Docker Compose dla konfiguracji początkowej

```yaml
version: '3.8'

services:
  # Ollama - lokalny model LLM
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped

  # MongoDB - baza dla Rocket.Chat
  mongo:
    image: mongo:5.0
    container_name: mongo
    volumes:
      - mongo_data:/data/db
    command: mongod --oplogSize 128
    restart: unless-stopped

  # Rocket.Chat - system komunikacji
  rocketchat:
    image: rocketchat/rocket.chat:latest
    container_name: rocketchat
    ports:
      - "3000:3000"
    environment:
      - PORT=3000
      - ROOT_URL=http://localhost:3000
      - MONGO_URL=mongodb://mongo:27017/rocketchat
      - MONGO_OPLOG_URL=mongodb://mongo:27017/local
      - ADMIN_USERNAME=admin
      - ADMIN_PASS=password
      - ADMIN_EMAIL=admin@example.com
    depends_on:
      - mongo
    restart: unless-stopped

  # Middleware API - komunikacja między usługami
  middleware-api:
    build:
      context: ./middleware-api
      dockerfile: Dockerfile
    container_name: middleware-api
    ports:
      - "5000:5000"
    volumes:
      - ./middleware-api:/app
    environment:
      - OLLAMA_API_URL=http://ollama:11434
      - ROCKETCHAT_URL=http://rocketchat:3000
    depends_on:
      - ollama
      - rocketchat
    restart: unless-stopped

volumes:
  ollama_data:
  mongo_data:
```

### 1.3. Struktura Folderu Początkowego

```
.
├── docker-compose.yml           # Plik konfiguracyjny Docker Compose
├── middleware-api/              # Warstwa pośrednia komunikująca komponenty
│   ├── Dockerfile               # Definicja obrazu Docker
│   ├── app.py                   # Główna aplikacja Flask/FastAPI
│   ├── autonomous_layer.py      # Warstwa autonomiczna
│   ├── docker_manager.py        # Zarządzanie usługami Docker
│   ├── ollama_client.py         # Klient API Ollama
│   └── rocketchat_client.py     # Klient API Rocket.Chat
├── data/                        # Folder na dane systemu
└── scripts/                     # Skrypty pomocnicze
    ├── setup.sh                 # Skrypt inicjalizacyjny
    └── backup.sh                # Skrypt tworzenia kopii zapasowych
```

## 2. Implementacja modułu middleware-api (kluczowy komponent)

### 2.1. Główna aplikacja API (app.py)

```python
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
import uvicorn
import logging
from typing import List, Dict, Any

from autonomous_layer import AutonomousLayer
from ollama_client import OllamaClient
from rocketchat_client import RocketChatClient
from docker_manager import DockerManager

# Konfiguracja logowania
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("system.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI(title="System Autonomiczny API")

# Inicjalizacja klientów
ollama_client = OllamaClient()
rocketchat_client = RocketChatClient()
docker_manager = DockerManager()
autonomous_layer = AutonomousLayer(ollama_client, rocketchat_client, docker_manager)

# Modele danych
class Message(BaseModel):
    user_id: str
    text: str
    room_id: str

class Task(BaseModel):
    title: str
    description: str
    priority: int = 1
    tags: List[str] = []
    user_id: str

class ServiceRequest(BaseModel):
    service_type: str
    description: str
    reason: str

# Endpointy API
@app.get("/")
def read_root():
    return {"status": "Online", "system": "Autonomiczny System"}

@app.get("/status")
def get_status():
    status = {
        "ollama": ollama_client.get_status(),
        "rocketchat": rocketchat_client.get_status(),
        "docker": docker_manager.get_status(),
        "services": docker_manager.list_services()
    }
    return status

@app.post("/message")
async def process_message(message: Message, background_tasks: BackgroundTasks):
    """Przetwarzanie wiadomości z Rocket.Chat"""
    logger.info(f"Otrzymano wiadomość: {message.text}")
    
    # Rozpoczęcie przetwarzania w tle
    background_tasks.add_task(
        autonomous_layer.process_message,
        message.user_id,
        message.text,
        message.room_id
    )
    
    return {"status": "accepted", "message": "Wiadomość została przyjęta do przetworzenia"}

@app.post("/task")
async def create_task(task: Task, background_tasks: BackgroundTasks):
    """Utworzenie nowego zadania"""
    logger.info(f"Utworzono zadanie: {task.title}")
    
    # Rozpoczęcie przetwarzania zadania w tle
    background_tasks.add_task(
        autonomous_layer.process_task,
        task.dict()
    )
    
    return {"status": "created", "task_id": "task_123"}  # W rzeczywistej implementacji ID zadania byłoby generowane

@app.post("/service")
async def add_service(service: ServiceRequest):
    """Dodanie nowej usługi Docker"""
    logger.info(f"Prośba o dodanie usługi: {service.service_type}")
    
    result = docker_manager.add_service(
        service.service_type,
        service.description,
        service.reason
    )
    
    if result.get("success", False):
        return {"status": "success", "service_id": result.get("service_id")}
    else:
        raise HTTPException(status_code=400, detail=result.get("error", "Unknown error"))

@app.get("/services")
def list_services():
    """Listowanie dostępnych usług Docker"""
    services = docker_manager.list_services()
    return {"services": services}

@app.get("/capabilities")
def get_capabilities():
    """Pobranie aktualnych możliwości systemu"""
    capabilities = autonomous_layer.get_capabilities()
    return {"capabilities": capabilities}

@app.post("/evolve")
async def evolve_system(background_tasks: BackgroundTasks):
    """Zainicjowanie procesu ewolucji systemu"""
    logger.info("Rozpoczęcie procesu ewolucji systemu")
    
    background_tasks.add_task(autonomous_layer.evolve_system)
    
    return {"status": "started", "message": "Rozpoczęto proces ewolucji systemu"}

if __name__ == "__main__":
    uvicorn.run("app:app", host="0.0.0.0", port=5000, reload=True)
```

### 2.2. Warstwa autonomiczna (autonomous_layer.py)

```python
import logging
import time
import threading
import asyncio
from typing import Dict, List, Any

logger = logging.getLogger(__name__)

class AutonomousLayer:
    """Centralna warstwa autonomiczna systemu"""
    
    def __init__(self, ollama_client, rocketchat_client, docker_manager):
        self.ollama_client = ollama_client
        self.rocketchat_client = rocketchat_client
        self.docker_manager = docker_manager
        self.capabilities = self._init_capabilities()
        self.evolution_level = 0
        self.lock = threading.Lock()
        
    def _init_capabilities(self) -> Dict[str, bool]:
        """Inicjalizacja bazowych możliwości systemu"""
        return {
            "chat": True,
            "voice": False,
            "code_generation": False,
            "data_analysis": False,
            "visualization": False,
            "version_control": False,
            "ci_cd": False,
            "advanced_automation": False
        }
        
    def get_capabilities(self) -> Dict[str, bool]:
        """Pobranie aktualnych możliwości systemu"""
        return self.capabilities
        
    async def process_message(self, user_id: str, text: str, room_id: str):
        """Przetwarzanie wiadomości od użytkownika"""
        logger.info(f"Przetwarzanie wiadomości od {user_id}: {text}")
        
        # Analiza wiadomości przez Ollama
        response = self.ollama_client.generate(
            prompt=f"User message: {text}\nYour task: Analyze this message and determine if it requires any system evolution or new capabilities.",
            model="llama3:7b"
        )
        
        # Sprawdzenie, czy wiadomość wymaga ewolucji systemu
        needs_evolution = self._check_evolution_needs(response, text)
        
        if needs_evolution:
            # Powiadomienie użytkownika o potrzebie ewolucji
            await self._notify_evolution_needed(user_id, room_id, needs_evolution)
        else:
            # Standardowa odpowiedź
            reply = self.ollama_client.generate(
                prompt=f"User message: {text}\nYour task: Respond to this message as a helpful assistant.",
                model="llama3:7b"
            )
            
            # Wysłanie odpowiedzi
            self.rocketchat_client.send_message(room_id, reply)
        
    def _check_evolution_needs(self, analysis: str, original_message: str) -> Dict:
        """Sprawdzenie, czy wiadomość sugeruje potrzebę ewolucji systemu"""
        # To jest uproszczona implementacja - w rzeczywistym systemie byłaby bardziej zaawansowana
        evolution_keywords = {
            "voice": ["głos", "mówić", "rozmawiać głosowo", "audio"],
            "code": ["kod", "programowanie", "aplikacja", "stworzyć program"],
            "data": ["dane", "analiza", "wykres", "statystyki", "csv", "excel"],
            "version_control": ["git", "wersja", "gitlab", "kontrola wersji"],
            "ci_cd": ["ci/cd", "continuous integration", "wdrożenie", "pipeline"]
        }
        
        needed_capabilities = {}
        
        for capability, keywords in evolution_keywords.items():
            if any(keyword in original_message.lower() for keyword in keywords):
                if not self.capabilities.get(capability, False):
                    needed_capabilities[capability] = True
                    
        return needed_capabilities
        
    async def _notify_evolution_needed(self, user_id: str, room_id: str, needed_capabilities: Dict[str, bool]):
        """Powiadomienie użytkownika o potrzebie ewolucji systemu"""
        capability_names = {
            "voice": "obsługa głosu (rozpoznawanie i synteza mowy)",
            "code": "środowisko programistyczne (generowanie i wykonywanie kodu)",
            "data": "analiza danych i wizualizacja",
            "version_control": "system kontroli wersji (GitLab)",
            "ci_cd": "automatyczne wdrażanie (CI/CD Pipeline)"
        }
        
        capabilities_text = ", ".join([capability_names[cap] for cap in needed_capabilities.keys()])
        
        message = f"""
Wykryłem, że do realizacji Twojego żądania potrzebuję dodatkowych możliwości, których obecnie nie posiadam.

Potrzebne możliwości: {capabilities_text}

Czy chcesz, abym zainstalował i skonfigurował te komponenty, aby móc lepiej Ci pomóc?
        """
        
        self.rocketchat_client.send_message(room_id, message)
        
    async def process_task(self, task: Dict):
        """Przetwarzanie zadania"""
        logger.info(f"Przetwarzanie zadania: {task['title']}")
        
        # Implementacja przetwarzania zadania
        # ...
        
    async def evolve_system(self):
        """Ewolucja systemu do kolejnego poziomu"""
        with self.lock:  # Zapobieganie jednoczesnym ewolucjom
            current_level = self.evolution_level
            next_level = current_level + 1
            
            logger.info(f"Rozpoczęcie ewolucji systemu z poziomu {current_level} do {next_level}")
            
            # Implementacja ewolucji zależna od poziomu
            if next_level == 1:
                await self._evolve_to_level_1()
            elif next_level == 2:
                await self._evolve_to_level_2()
            elif next_level == 3:
                await self._evolve_to_level_3()
            elif next_level == 4:
                await self._evolve_to_level_4()
            else:
                logger.warning(f"Nieznany poziom ewolucji: {next_level}")
                return
                
            # Aktualizacja poziomu ewolucji
            self.evolution_level = next_level
            logger.info(f"Zakończono ewolucję do poziomu {next_level}")
            
    async def _evolve_to_level_1(self):
        """Ewolucja do poziomu 1: Komunikacja rozszerzona"""
        logger.info("Ewolucja do poziomu 1: Dodawanie obsługi głosu")
        
        # Dodanie usług STT/TTS
        self.docker_manager.add_service(
            "stt",
            "Usługa rozpoznawania mowy (Vosk)",
            "Potrzebna do obsługi komunikacji głosowej"
        )
        
        self.docker_manager.add_service(
            "tts",
            "Usługa syntezy mowy (Mozilla TTS)",
            "Potrzebna do obsługi komunikacji głosowej"
        )
        
        # Aktualizacja możliwości
        self.capabilities["voice"] = True
        
        # Powiadomienie o zakończeniu ewolucji
        # ...
        
    async def _evolve_to_level_2(self):
        """Ewolucja do poziomu 2: Środowisko programistyczne"""
        logger.info("Ewolucja do poziomu 2: Dodawanie środowiska programistycznego")
        
        # Dodanie VS Code Server
        self.docker_manager.add_service(
            "code-server",
            "VS Code Server z rozszerzeniami",
            "Środowisko programistyczne do generowania i wykonywania kodu"
        )
        
        # Dodanie GitLab
        self.docker_manager.add_service(
            "gitlab",
            "GitLab CE (system kontroli wersji)",
            "System kontroli wersji do zarządzania kodem"
        )
        
        # Aktualizacja możliwości
        self.capabilities["code_generation"] = True
        self.capabilities["version_control"] = True
        
        # Powiadomienie o zakończeniu ewolucji
        # ...
        
    async def _evolve_to_level_3(self):
        """Ewolucja do poziomu 3: Zaawansowana automatyzacja"""
        logger.info("Ewolucja do poziomu 3: Dodawanie zaawansowanej automatyzacji")
        
        # Dodanie serwera CI/CD
        self.docker_manager.add_service(
            "gitlab-runner",
            "GitLab Runner (CI/CD)",
            "Runner dla zadań CI/CD w GitLab"
        )
        
        # Dodanie narzędzi do analizy danych
        self.docker_manager.add_service(
            "jupyter",
            "Jupyter Notebook Server",
            "Środowisko do analizy danych i wizualizacji"
        )
        
        # Dodanie bazy danych
        self.docker_manager.add_service(
            "postgres",
            "PostgreSQL Database",
            "Baza danych do przechowywania danych projektów"
        )
        
        # Aktualizacja możliwości
        self.capabilities["ci_cd"] = True
        self.capabilities["data_analysis"] = True
        self.capabilities["visualization"] = True
        
        # Powiadomienie o zakończeniu ewolucji
        # ...
        
    async def _evolve_to_level_4(self):
        """Ewolucja do poziomu 4: Pełna autonomia"""
        logger.info("Ewolucja do poziomu 4: Dodawanie pełnej autonomii")
        
        # Dodanie menedżera zasobów
        self.docker_manager.add_service(
            "resource-manager",
            "Menedżer zasobów systemu",
            "Automatyczne zarządzanie zasobami sprzętowymi"
        )
        
        # Dodanie systemu monitoringu
        self.docker_manager.add_service(
            "prometheus",
            "Prometheus Monitoring",
            "System monitorowania usług i zasobów"
        )
        
        self.docker_manager.add_service(
            "grafana",
            "Grafana Dashboard",
            "Wizualizacja metryk z Prometheus"
        )
        
        # Dodanie mechanizmu uczenia na podstawie interakcji
        self.docker_manager.add_service(
            "learning-system",
            "System uczenia się preferencji użytkownika",
            "Adaptacja systemu do wzorców użytkowania"
        )
        
        # Aktualizacja możliwości
        self.capabilities["advanced_automation"] = True
        
        # Powiadomienie o zakończeniu ewolucji
        # ...
```

### 2.3. Zarządzanie usługami Docker (docker_manager.py)

```python
import logging
import docker
import yaml
import os
import uuid
from typing import Dict, List, Any

logger = logging.getLogger(__name__)

class DockerManager:
    """Klasa do zarządzania usługami Docker w systemie autonomicznym"""
    
    def __init__(self, compose_file: str = "docker-compose.yml"):
        self.compose_file = compose_file
        self.client = docker.from_env()
        self.service_templates = self._load_service_templates()
        
    def _load_service_templates(self) -> Dict[str, Dict]:
        """Ładowanie szablonów usług Docker"""
        # W rzeczywistej implementacji szablony mogłyby być ładowane z pliku
        return {
            # Szablony usług komunikacyjnych
            "stt": {
                "image": "alphacep/kaldi-vosk-server:latest",
                "ports": ["2700:2700"],
                "volumes": ["./models:/opt/vosk-model"],
                "restart": "unless-stopped"
            },
            "tts": {
                "image": "synesthesiam/mozilla-tts:latest",
                "ports": ["5002:5002"],
                "restart": "unless-stopped"
            },
            
            # Szablony środowiska programistycznego
            "code-server": {
                "image": "linuxserver/code-server:latest",
                "ports": ["8443:8443"],
                "volumes": [
                    "./vscode-config:/config",
                    "./workspace:/config/workspace"
                ],
                "environment": {
                    "PUID": "1000",
                    "PGID": "1000",
                    "TZ": "Europe/Warsaw",
                    "PASSWORD": "password123"  # Powinno być zabezpieczone w produkcji
                },
                "restart": "unless-stopped"
            },
            "gitlab": {
                "image": "gitlab/gitlab-ce:latest",
                "ports": ["8080:80", "8022:22"],
                "volumes": [
                    "gitlab_config:/etc/gitlab",
                    "gitlab_logs:/var/log/gitlab",
                    "gitlab_data:/var/opt/gitlab"
                ],
                "environment": {
                    "GITLAB_OMNIBUS_CONFIG": (
                        "external_url 'http://localhost:8080'\n"
                        "gitlab_rails['gitlab_shell_ssh_port'] = 8022\n"
                    )
                },
                "restart": "unless-stopped"
            },
            
            # Szablony CI/CD
            "gitlab-runner": {
                "image": "gitlab/gitlab-runner:latest",
                "volumes": [
                    "/var/run/docker.sock:/var/run/docker.sock",
                    "gitlab_runner_config:/etc/gitlab-runner"
                ],
                "restart": "unless-stopped",
                "depends_on": ["gitlab"]
            },
            
            # Szablony analizy danych
            "jupyter": {
                "image": "jupyter/datascience-notebook:latest",
                "ports": ["8888:8888"],
                "volumes": ["./jupyter-notebooks:/home/jovyan/work"],
                "environment": {
                    "JUPYTER_ENABLE_LAB": "yes"
                },
                "restart": "unless-stopped"
            },
            "postgres": {
                "image": "postgres:14",
                "ports": ["5432:5432"],
                "volumes": ["postgres_data:/var/lib/postgresql/data"],
                "environment": {
                    "POSTGRES_PASSWORD": "postgres",
                    "POSTGRES_USER": "postgres",
                    "POSTGRES_DB": "default"
                },
                "restart": "unless-stopped"
            },
            
            # Szablony monitorowania
            "prometheus": {
                "image": "prom/prometheus:latest",
                "ports": ["9090:9090"],
                "volumes": ["./prometheus-config:/etc/prometheus"],
                "restart": "unless-stopped"
            },
            "grafana": {
                "image": "grafana/grafana:latest",
                "ports": ["3001:3000"],
                "volumes": ["grafana_data:/var/lib/grafana"],
                "restart": "unless-stopped",
                "depends_on": ["prometheus"]
            },
            
            # Inne szablony usług
            "learning-system": {
                "build": {
                    "context": "./learning-system",
                    "dockerfile": "Dockerfile"
                },
                "volumes": ["./learning-system:/app"],
                "restart": "unless-stopped"
            },
            "resource-manager": {
                "build": {
                    "context": "./resource-manager",
                    "dockerfile": "Dockerfile"
                },
                "volumes": [
                    "/var/run/docker.sock:/var/run/docker.sock",
                    "./resource-manager:/app"
                ],
                "restart": "unless-stopped"
            }
        }
        
    def load_compose_file(self) -> Dict:
        """Ładowanie istniejącego pliku docker-compose.yml"""
        if os.path.exists(self.compose_file):
            with open(self.compose_file, 'r') as f:
                return yaml.safe_load(f) or {"version": "3.8", "services": {}}
        else:
            return {"version": "3.8", "services": {}}
        
    def save_compose_file(self, compose_data: Dict):
        """Zapisanie danych do pliku docker-compose.yml"""
        with open(self.compose_file, 'w') as f:
            yaml.dump(compose_data, f, default_flow_style=False)
            
    def get_status(self) -> Dict:
        """Pobranie statusu menedżera Docker"""
        try:
            info = self.client.info()
            return {
                "status": "ok",
                "containers": len(self.client.containers.list()),
                "version": info.get("ServerVersion", "unknown")
            }
        except Exception as e:
            logger.error(f"Błąd podczas pobierania statusu Docker: {str(e)}")
            return {"status": "error", "error": str(e)}
        
    def list_services(self) -> List[Dict]:
        """Listowanie dostępnych usług Docker"""
        compose_data = self.load_compose_file()
        services = []
        
        for service_name, service_config in compose_data.get("services", {}).items():
            # Pobranie statusu usługi (czy działa)
            status = "unknown"
            try:
                containers = self.client.containers.list(
                    filters={"name": service_name}
                )
                if containers:
                    status = containers[0].status
            except Exception:
                pass
            
            services.append({
                "name": service_name,
                "image": service_config.get("image", "custom"),
                "status": status
            })
            
        return services
        
    def add_service(self, service_type: str, description: str, reason: str) -> Dict:
        """Dodanie nowej usługi Docker"""
        logger.info(f"Dodawanie usługi typu {service_type}: {description}")
        
        # Sprawdzenie czy szablon usługi istnieje
        if service_type not in self.service_templates:
            return {
                "success": False,
                "error": f"Nieznany typ usługi: {service_type}"
            }
            
        # Generowanie unikalnego ID dla usługi
        service_id = str(uuid.uuid4())[:8]
        service_name = f"{service_type}_{service_id}"
        
        # Ładowanie aktualnej konfiguracji
        compose_data = self.load_compose_file()
        
        # Sprawdzenie czy usługa już istnieje
        if service_name in compose_data.get("services", {}):
            return {
                "success": False,
                "error": f"Usługa o nazwie {service_name} już istnieje"
            }
            
        # Tworzenie konfiguracji usługi
        service_config = self.service_templates[service_type].copy()
        
        # Dodanie usługi do konfiguracji
        if "services" not in compose_data:
            compose_data["services"] = {}
            
        compose_data["services"][service_name] = service_config
        
        # Sprawdzenie, czy potrzebne są dodatkowe wolumeny
        volumes_in_service = self._extract_volumes_from_service(service_config)
        
        # Dodanie wolumenów do konfiguracji
        if volumes_in_service and "volumes" not in compose_data:
            compose_data["volumes"] = {}
            
        for volume in volumes_in_service:
            if volume not in compose_data.get("volumes", {}):
                compose_data["volumes"][volume] = {}
                
        # Zapisanie zmian
        self.save_compose_file(compose_data)
        
        # Próba uruchomienia usługi
        try:
            import subprocess
            result = subprocess.run(
                f"docker-compose -f {self.compose_file} up -d {service_name}",
                shell=True,
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                logger.error(f"Błąd podczas uruchamiania usługi: {result.stderr}")
                return {
                    "success": True,  # Usługa została dodana, ale nie uruchomiona
                    "service_id": service_name,
                    "warning": f"Usługa została dodana, ale wystąpił błąd podczas uruchamiania: {result.stderr}"
                }
        except Exception as e:
            logger.error(f"Wyjątek podczas uruchamiania usługi: {str(e)}")
            return {
                "success": True,  # Usługa została dodana, ale nie uruchomiona
                "service_id": service_name,
                "warning": f"Usługa została dodana, ale wystąpił błąd podczas uruchamiania: {str(e)}"
            }
            
        return {
            "success": True,
            "service_id": service_name,
            "message": f"Usługa {service_name} została dodana i uruchomiona"
        }
        
    def _extract_volumes_from_service(self, service_config: Dict) -> List[str]:
        """Wyodrębnienie nazw wolumenów z konfiguracji usługi"""
        volumes = []
        
        if "volumes" in service_config:
            for volume in service_config["volumes"]:
                # Sprawdzenie czy to jest zapis wolumenu nazwowego (nie ścieżka)
                if ":" in volume and not volume.startswith("./") and not volume.startswith("/"):
                    volume_name = volume.split(":")[0]
                    volumes.append(volume_name)
                    
        return volumes
        
    def remove_service(self, service_name: str) -> Dict:
        """Usunięcie usługi Docker"""
        logger.info(f"Usuwanie usługi {service_name}")
        
        # Ładowanie aktualnej konfiguracji
        compose_data = self.load_compose_file()
        
        # Sprawdzenie czy usługa istnieje
        if service_name not in compose_data.get("services", {}):
            return {
                "success": False,
                "error": f"Usługa o nazwie {service_name} nie istnieje"
            }
            
        # Zatrzymanie i usunięcie kontenerów
        try:
            import subprocess
            result = subprocess.run(
                f"docker-compose -f {self.compose_file} rm -sf {service_name}",
                shell=True,
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                logger.error(f"Błąd podczas usuwania kontenerów: {result.stderr}")
        except Exception as e:
            logger.error(f"Wyjątek podczas usuwania kontenerów: {str(e)}")
            
        # Usunięcie usługi z konfiguracji
        del compose_data["services"][service_name]
        
        # Zapisanie zmian
        self.save_compose_file(compose_data)
        
        return {
            "success": True,
            "message": f"Usługa {service_name} została usunięta"
        }
```

### 2.4. Klient Ollama (ollama_client.py)

```python
import requests
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

class OllamaClient:
    """Klient API dla modelu Ollama"""
    
    def __init__(self, base_url: str = "http://ollama:11434"):
        self.base_url = base_url
        
    def get_status(self) -> Dict:
        """Sprawdzenie statusu Ollama"""
        try:
            response = requests.get(f"{self.base_url}/api/tags")
            if response.status_code == 200:
                return {"status": "ok", "models": len(response.json().get("models", []))}
            else:
                return {"status": "error", "error": f"HTTP {response.status_code}"}
        except Exception as e:
            logger.error(f"Błąd podczas sprawdzania statusu Ollama: {str(e)}")
            return {"status": "error", "error": str(e)}
            
    def generate(self, prompt: str, model: str = "llama3:7b", system: Optional[str] = None) -> str:
        """Generowanie tekstu przez model Ollama"""
        try:
            data = {
                "model": model,
                "prompt": prompt,
                "stream": False
            }
            
            if system:
                data["system"] = system
                
            response = requests.post(
                f"{self.base_url}/api/generate",
                json=data
            )
            
            if response.status_code == 200:
                return response.json().get("response", "")
            else:
                logger.error(f"Błąd odpowiedzi Ollama: {response.text}")
                return f"Error: {response.status_code}"
                
        except Exception as e:
            logger.error(f"Wyjątek podczas generowania tekstu: {str(e)}")
            return f"Error: {str(e)}"
            
    def chat(self, messages: list, model: str = "llama3:7b") -> str:
        """Wywołanie API czatu Ollama"""
        try:
            data = {
                "model": model,
                "messages": messages,
                "stream": False
            }
            
            response = requests.post(
                f"{self.base_url}/api/chat",
                json=data
            )
            
            if response.status_code == 200:
                return response.json().get("message", {}).get("content", "")
            else:
                logger.error(f"Błąd odpowiedzi Ollama: {response.text}")
                return f"Error: {response.status_code}"
                
        except Exception as e:
            logger.error(f"Wyjątek podczas wywołania czatu: {str(e)}")
            return f"Error: {str(e)}"
            
    def list_models(self) -> list:
        """Pobranie listy dostępnych modeli"""
        try:
            response = requests.get(f"{self.base_url}/api/tags")
            
            if response.status_code == 200:
                return response.json().get("models", [])
            else:
                logger.error(f"Błąd odpowiedzi Ollama: {response.text}")
                return []
                
        except Exception as e:
            logger.error(f"Wyjątek podczas listowania modeli: {str(e)}")
            return []
            
    def pull_model(self, model_name: str) -> bool:
        """Pobranie modelu przez Ollama"""
        try:
            data = {
                "name": model_name
            }
            
            response = requests.post(
                f"{self.base_url}/api/pull",
                json=data
            )
            
            return response.status_code == 200
            
        except Exception as e:
            logger.error(f"Wyjątek podczas pobierania modelu: {str(e)}")
            return False
```

### 2.5. Klient Rocket.Chat (rocketchat_client.py)

```python
import requests
import logging
from typing import Dict, Any, List, Optional

logger = logging.getLogger(__name__)

class RocketChatClient:
    """Klient API dla Rocket.Chat"""
    
    def __init__(self, base_url: str = "http://rocketchat:3000", 
                 username: str = "admin", password: str = "password"):
        self.base_url = base_url
        self.username = username
        self.password = password
        self.auth_token = None
        self.user_id = None
        
    def get_status(self) -> Dict:
        """Sprawdzenie statusu Rocket.Chat"""
        try:
            response = requests.get(f"{self.base_url}/api/info")
            if response.status_code == 200:
                return {"status": "ok", "version": response.json().get("version", "unknown")}
            else:
                return {"status": "error", "error": f"HTTP {response.status_code}"}
        except Exception as e:
            logger.error(f"Błąd podczas sprawdzania statusu Rocket.Chat: {str(e)}")
            return {"status": "error", "error": str(e)}
            
    def login(self) -> bool:
        """Logowanie do Rocket.Chat"""
        if self.auth_token and self.user_id:
            return True
            
        try:
            response = requests.post(
                f"{self.base_url}/api/v1/login",
                json={
                    "username": self.username,
                    "password": self.password
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                if data.get("status") == "success":
                    self.auth_token = data.get("data", {}).get("authToken")
                    self.user_id = data.get("data", {}).get("userId")
                    return True
                    
            logger.error(f"Błąd logowania do Rocket.Chat: {response.text}")
            return False
            
        except Exception as e:
            logger.error(f"Wyjątek podczas logowania do Rocket.Chat: {str(e)}")
            return False
            
    def get_headers(self) -> Dict:
        """Pobranie nagłówków autoryzacyjnych"""
        if not self.auth_token or not self.user_id:
            if not self.login():
                return {}
                
        return {
            "X-Auth-Token": self.auth_token,
            "X-User-Id": self.user_id,
            "Content-Type": "application/json"
        }
        
    def send_message(self, room_id: str, text: str) -> bool:
        """Wysłanie wiadomości na kanał"""
        headers = self.get_headers()
        if not headers:
            return False
            
        try:
            response = requests.post(
                f"{self.base_url}/api/v1/chat.postMessage",
                headers=headers,
                json={
                    "roomId": room_id,
                    "text": text
                }
            )
            
            return response.status_code == 200
            
        except Exception as e:
            logger.error(f"Wyjątek podczas wysyłania wiadomości: {str(e)}")
            return False
            
    def create_channel(self, name: str, members: Optional[List[str]] = None, 
                      private: bool = False) -> Dict:
        """Utworzenie nowego kanału"""
        headers = self.get_headers()
        if not headers:
            return {"success": False, "error": "Not authenticated"}
            
        try:
            url = f"{self.base_url}/api/v1/{'groups' if private else 'channels'}.create"
            
            data = {
                "name": name
            }
            
            if members:
                data["members"] = members
                
            response = requests.post(
                url,
                headers=headers,
                json=data
            )
            
            if response.status_code == 200:
                return {"success": True, "data": response.json()}
            else:
                return {"success": False, "error": response.text}
                
        except Exception as e:
            logger.error(f"Wyjątek podczas tworzenia kanału: {str(e)}")
            return {"success": False, "error": str(e)}
            
    def get_channel_id(self, channel_name: str) -> Optional[str]:
        """Pobranie ID kanału na podstawie nazwy"""
        headers = self.get_headers()
        if not headers:
            return None
            
        try:
            # Próba pobrania publicznego kanału
            response = requests.get(
                f"{self.base_url}/api/v1/channels.info?roomName={channel_name}",
                headers=headers
            )
            
            if response.status_code == 200:
                return response.json().get("channel", {}).get("_id")
                
            # Próba pobrania prywatnego kanału
            response = requests.get(
                f"{self.base_url}/api/v1/groups.info?roomName={channel_name}",
                headers=headers
            )
            
            if response.status_code == 200:
                return response.json().get("group", {}).get("_id")
                
            return None
            
        except Exception as e:
            logger.error(f"Wyjątek podczas pobierania ID kanału: {str(e)}")
            return None
```

## 3. Dockerfile dla middleware-api

```dockerfile
FROM python:3.9-slim

WORKDIR /app

# Instalacja zależności systemowych
RUN apt-get update && apt-get install -y \
    git \
    curl \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Kopiowanie plików wymagań
COPY requirements.txt .

# Instalacja zależności Pythona
RUN pip install --no-cache-dir -r requirements.txt

# Kopiowanie kodu aplikacji
COPY . .

# Nadanie uprawnień wykonawczych dla skryptów
RUN chmod +x /app/scripts/*.sh

# Ustawienie zmiennych środowiskowych
ENV PYTHONUNBUFFERED=1

# Ekspozycja portu
EXPOSE 5000

# Uruchomienie aplikacji
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "5000"]
```

## 4. Plik requirements.txt dla middleware-api

```
fastapi>=0.68.0
uvicorn>=0.15.0
docker>=5.0.0
pyyaml>=6.0
requests>=2.26.0
python-dotenv>=0.19.0
pydantic>=1.8.2
websockets>=10.0
pytz>=2021.3
aiohttp>=3.8.0
```

## 5. Skrypt inicjalizacyjny (setup.sh)

```bash
#!/bin/bash

# Skrypt inicjalizacyjny dla systemu autonomicznego

# Kolory dla lepszej czytelności
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
NC='\033[0m' # No Color

# Banner
echo -e "${GREEN}"
echo "=================================="
echo " System Autonomiczny - Inicjalizacja"
echo "=================================="
echo -e "${NC}"

# Sprawdzenie wymagań
echo -e "${YELLOW}Sprawdzanie wymagań...${NC}"

# Docker
if ! command -v docker &> /dev/null; then
    echo -e "${RED}Docker nie jest zainstalowany. Proszę zainstalować Docker przed kontynuacją.${NC}"
    exit 1
fi

# Docker Compose
if ! command -v docker-compose &> /dev/null; then
    echo -e "${RED}Docker Compose nie jest zainstalowany. Proszę zainstalować Docker Compose przed kontynuacją.${NC}"
    exit 1
fi

echo -e "${GREEN}Wszystkie wymagania spełnione.${NC}"

# Tworzenie struktury katalogów
echo -e "${YELLOW}Tworzenie struktury katalogów...${NC}"

mkdir -p data/ollama
mkdir -p data/mongo
mkdir -p middleware-api
mkdir -p scripts

echo -e "${GREEN}Struktura katalogów utworzona.${NC}"

# Tworzenie pliku docker-compose.yml
echo -e "${YELLOW}Tworzenie pliku docker-compose.yml...${NC}"

cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  # Ollama - lokalny model LLM
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped

  # MongoDB - baza dla Rocket.Chat
  mongo:
    image: mongo:5.0
    container_name: mongo
    volumes:
      - mongo_data:/data/db
    command: mongod --oplogSize 128
    restart: unless-stopped

  # Rocket.Chat - system komunikacji
  rocketchat:
    image: rocketchat/rocket.chat:latest
    container_name: rocketchat
    ports:
      - "3000:3000"
    environment:
      - PORT=3000
      - ROOT_URL=http://localhost:3000
      - MONGO_URL=mongodb://mongo:27017/rocketchat
      - MONGO_OPLOG_URL=mongodb://mongo:27017/local
      - ADMIN_USERNAME=admin
      - ADMIN_PASS=password
      - ADMIN_EMAIL=admin@example.com
    depends_on:
      - mongo
    restart: unless-stopped

  # Middleware API - komunikacja między usługami
  middleware-api:
    build:
      context: ./middleware-api
      dockerfile: Dockerfile
    container_name: middleware-api
    ports:
      - "5000:5000"
    volumes:
      - ./middleware-api:/app
    environment:
      - OLLAMA_API_URL=http://ollama:11434
      - ROCKETCHAT_URL=http://rocketchat:3000
    depends_on:
      - ollama
      - rocketchat
    restart: unless-stopped

volumes:
  ollama_data:
  mongo_data:
EOF

echo -e "${GREEN}Plik docker-compose.yml utworzony.${NC}"

# Tworzenie plików middleware-api
echo -e "${YELLOW}Tworzenie plików middleware-api...${NC}"

# Tworzenie pliku requirements.txt
cat > middleware-api/requirements.txt << 'EOF'
fastapi>=0.68.0
uvicorn>=0.15.0
docker>=5.0.0
pyyaml>=6.0
requests>=2.26.0
python-dotenv>=0.19.0
pydantic>=1.8.2
websockets>=10.0
pytz>=2021.3
aiohttp>=3.8.0
EOF

# Tworzenie pliku Dockerfile
cat > middleware-api/Dockerfile << 'EOF'
FROM python:3.9-slim

WORKDIR /app

# Instalacja zależności systemowych
RUN apt-get update && apt-get install -y \
    git \
    curl \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Kopiowanie plików wymagań
COPY requirements.txt .

# Instalacja zależności Pythona
RUN pip install --no-cache-dir -r requirements.txt

# Kopiowanie kodu aplikacji
COPY . .

# Nadanie uprawnień wykonawczych dla skryptów
RUN chmod +x /app/scripts/*.sh 2>/# Plan Implementacji Systemu Autonomicznego

## 1. Konfiguracja Początkowa (System Minimalny)

### 1.1. Komponenty Bazowe
- **Docker Compose** - podstawowy plik do uruchomienia minimalnego zestawu usług
- **Rocket.Chat** - podstawowy system komunikacji
- **Ollama** - lokalny model LLM
- **Warstwa autonomiczna** - podstawowy system podejmowania decyzji

### 1.2. Plik Docker Compose dla konfiguracji początkowej

```yaml
version: '3.8'

services:
  # Ollama - lokalny model LLM
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped

  # MongoDB - baza dla Rocket.Chat
  mongo:
    image: mongo:5.0
    container_name: mongo
    volumes:
      - mongo_data:/data/db
    command: mongod --oplogSize 128
    restart: unless-stopped

  # Rocket.Chat - system komunikacji
  rocketchat:
    image: rocketchat/rocket.chat:latest
    container_name: rocketchat
    ports:
      - "3000:3000"
    environment:
      - PORT=3000
      - ROOT_URL=http://localhost:3000
      - MONGO_URL=mongodb://mongo:27017/rocketchat
      - MONGO_OPLOG_URL=mongodb://mongo:27017/local
      - ADMIN_USERNAME=admin
      - ADMIN_PASS=password
      - ADMIN_EMAIL=admin@example.com
    depends_on:
      - mongo
    restart: unless-stopped

  # Middleware API - komunikacja między usługami
  middleware-api:
    build:
      context: ./middleware-api
      dockerfile: Dockerfile
    container_name: middleware-api
    ports:
      - "5000:5000"
    volumes:
      - ./middleware-api:/app
    environment:
      - OLLAMA_API_URL=http://ollama:11434
      - ROCKETCHAT_URL=http://rocketchat:3000
    depends_on:
      - ollama
      - rocketchat
    restart: unless-stopped

volumes:
  ollama_data:
  mongo_data:
```

### 1.3. Struktura Folderu Początkowego

```
.
├── docker-compose.yml           # Plik konfiguracyjny Docker Compose
├── middleware-api/              # Warstwa pośrednia komunikująca komponenty
│   ├── Dockerfile               # Definicja obrazu Docker
│   ├── app.py                   # Główna aplikacja Flask/FastAPI
│   ├── autonomous_layer.py      # Warstwa autonomiczna
│   ├── docker_manager.py        # Zarządzanie usługami Docker
│   ├── ollama_client.py         # Klient API Ollama
│   └── rocketchat_client.py     # Klient API Rocket.Chat
├── data/                        # Folder na dane systemu
└── scripts/                     # Skrypty pomocnicze
    ├── setup.sh                 # Skrypt inicjalizacyjny
    └── backup.sh                # Skrypt tworzenia kopii zapasowych
```

## 2. Implementacja modułu middleware-api (kluczowy komponent)

### 2.1. Główna aplikacja API (app.py)

```python
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
import uvicorn
import logging
from typing import List, Dict, Any

from autonomous_layer import AutonomousLayer
from ollama_client import OllamaClient
from rocketchat_client import RocketChatClient
from docker_manager import DockerManager

# Konfiguracja logowania
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("system.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI(title="System Autonomiczny API")

# Inicjalizacja klientów
ollama_client = OllamaClient()
rocketchat_client = RocketChatClient()
docker_manager = DockerManager()
autonomous_layer = AutonomousLayer(ollama_client, rocketchat_client, docker_manager)

# Modele danych
class Message(BaseModel):
    user_id: str
    text: str
    room_id: str

class Task(BaseModel):
    title: str
    description: str
    priority: int = 1
    tags: List[str] = []
    user_id: str

class ServiceRequest(BaseModel):
    service_type: str
    description: str
    reason: str

# Endpointy API
@app.get("/")
def read_root():
    return {"status": "Online", "system": "Autonomiczny System"}

@app.get("/status")
def get_status():
    status = {
        "ollama": ollama_client.get_status(),
        "rocketchat": rocketchat_client.get_status(),
        "docker": docker_manager.get_status(),
        "services": docker_manager.list_services()
    }
    return status

@app.post("/message")
async def process_message(message: Message, background_tasks: BackgroundTasks):
    """Przetwarzanie wiadomości z Rocket.Chat"""
    logger.info(f"Otrzymano wiadomość: {message.text}")
    
    # Rozpoczęcie przetwarzania w tle
    background_tasks.add_task(
        autonomous_layer.process_message,
        message.user_id,
        message.text,
        message.room_id
    )
    
    return {"status": "accepted", "message": "Wiadomość została przyjęta do przetworzenia"}

@app.post("/task")
async def create_task(task: Task, background_tasks: BackgroundTasks):
    """Utworzenie nowego zadania"""
    logger.info(f"Utworzono zadanie: {task.title}")
    
    # Rozpoczęcie przetwarzania zadania w tle
    background_tasks.add_task(
        autonomous_layer.process_task,
        task.dict()
    )
    
    return {"status": "created", "task_id": "task_123"}  # W rzeczywistej implementacji ID zadania byłoby generowane

@app.post("/service")
async def add_service(service: ServiceRequest):
    """Dodanie nowej usługi Docker"""
    logger.info(f"Prośba o dodanie usługi: {service.service_type}")
    
    result = docker_manager.add_service(
        service.service_type,
        service.description,
        service.reason
    )
    
    if result.get("success", False):
        return {"status": "success", "service_id": result.get("service_id")}
    else:
        raise HTTPException(status_code=400, detail=result.get("error", "Unknown error"))

@app.get("/services")
def list_services():
    """Listowanie dostępnych usług Docker"""
    services = docker_manager.list_services()
    return {"services": services}

@app.get("/capabilities")
def get_capabilities():
    """Pobranie aktualnych możliwości systemu"""
    capabilities = autonomous_layer.get_capabilities()
    return {"capabilities": capabilities}

@app.post("/evolve")
async def evolve_system(background_tasks: BackgroundTasks):
    """Zainicjowanie procesu ewolucji systemu"""
    logger.info("Rozpoczęcie procesu ewolucji systemu")
    
    background_tasks.add_task(autonomous_layer.evolve_system)
    
    return {"status": "started", "message": "Rozpoczęto proces ewolucji systemu"}

if __name__ == "__main__":
    uvicorn.run("app:app", host="0.0.0.0", port=5000, reload=True)
```

### 2.2. Warstwa autonomiczna (autonomous_layer.py)

```python
import logging
import time
import threading
import asyncio
from typing import Dict, List, Any

logger = logging.getLogger(__name__)

class AutonomousLayer:
    """Centralna warstwa autonomiczna systemu"""
    
    def __init__(self, ollama_client, rocketchat_client, docker_manager):
        self.ollama_client = ollama_client
        self.rocketchat_client = rocketchat_client
        self.docker_manager = docker_manager
        self.capabilities = self._init_capabilities()
        self.evolution_level = 0
        self.lock = threading.Lock()
        
    def _init_capabilities(self) -> Dict[str, bool]:
        """Inicjalizacja bazowych możliwości systemu"""
        return {
            "chat": True,
            "voice": False,
            "code_generation": False,
            "data_analysis": False,
            "visualization": False,
            "version_control": False,
            "ci_cd": False,
            "advanced_automation": False
        }
        
    def get_capabilities(self) -> Dict[str, bool]:
        """Pobranie aktualnych możliwości systemu"""
        return self.capabilities
        
    async def process_message(self, user_id: str, text: str, room_id: str):
        """Przetwarzanie wiadomości od użytkownika"""
        logger.info(f"Przetwarzanie wiadomości od {user_id}: {text}")
        
        # Analiza wiadomości przez Ollama
        response = self.ollama_client.generate(
            prompt=f"User message: {text}\nYour task: Analyze this message and determine if it requires any system evolution or new capabilities.",
            model="llama3:7b"
        )
        
        # Sprawdzenie, czy wiadomość wymaga ewolucji systemu
        needs_evolution = self._check_evolution_needs(response, text)
        
        if needs_evolution:
            # Powiadomienie użytkownika o potrzebie ewolucji
            await self._notify_evolution_needed(user_id, room_id, needs_evolution)
        else:
            # Standardowa odpowiedź
            reply = self.ollama_client.generate(
                prompt=f"User message: {text}\nYour task: Respond to this message as a helpful assistant.",
                model="llama3:7b"
            )
            
            # Wysłanie odpowiedzi
            self.rocketchat_client.send_message(room_id, reply)
        
    def _check_evolution_needs(self, analysis: str, original_message: str) -> Dict:
        """Sprawdzenie, czy wiadomość sugeruje potrzebę ewolucji systemu"""
        # To jest uproszczona implementacja - w rzeczywistym systemie byłaby bardziej zaawansowana
        evolution_keywords = {
            "voice": ["głos", "mówić", "rozmawiać głosowo", "audio"],
            "code": ["kod", "programowanie", "aplikacja", "stworzyć program"],
            "data": ["dane", "analiza", "wykres", "statystyki", "csv", "excel"],
            "version_control": ["git", "wersja", "gitlab", "kontrola wersji"],
            "ci_cd": ["ci/cd", "continuous integration", "wdrożenie", "pipeline"]
        }
        
        needed_capabilities = {}
        
        for capability, keywords in evolution_keywords.items():
            if any(keyword in original_message.lower() for keyword in keywords):
                if not self.capabilities.get(capability, False):
                    needed_capabilities[capability] = True
                    
        return needed_capabilities
        
    async def _notify_evolution_needed(self, user_id: str, room_id: str, needed_capabilities: Dict[str, bool]):
        """Powiadomienie użytkownika o potrzebie ewolucji systemu"""
        capability_names = {
            "voice": "obsługa głosu (rozpoznawanie i synteza mowy)",
            "code": "środowisko programistyczne (generowanie i wykonywanie kodu)",
            "data": "analiza danych i wizualizacja",
            "version_control": "system kontroli wersji (GitLab)",
            "ci_cd": "automatyczne wdrażanie (CI/CD Pipeline)"
        }
        
        capabilities_text = ", ".join([capability_names[cap] for cap in needed_capabilities.keys()])
        
        message = f"""
Wykryłem, że do realizacji Twojego żądania potrzebuję dodatkowych możliwości, których obecnie nie posiadam.

Potrzebne możliwości: {capabilities_text}

Czy chcesz, abym zainstalował i skonfigurował te komponenty, aby móc lepiej Ci pomóc?
        """
        
        self.rocketchat_client.send_message(room_id, message)
        
    async def process_task(self, task: Dict):
        """Przetwarzanie zadania"""
        logger.info(f"Przetwarzanie zadania: {task['title']}")
        
        # Implementacja przetwarzania zadania
        # ...
        
    async def evolve_system(self):
        """Ewolucja systemu do kolejnego poziomu"""
        with self.lock:  # Zapobieganie jednoczesnym ewolucjom
            current_level = self.evolution_level
            next_level = current_level + 1
            
            logger.info(f"Rozpoczęcie ewolucji systemu z poziomu {current_level} do {next_level}")
            
            # Implementacja ewolucji zależna od poziomu
            if next_level == 1:
                await self._evolve_to_level_1()
            elif next_level == 2:
                await self._evolve_to_level_2()
            elif next_level == 3:
                await self._evolve_to_level_3()
            elif next_level == 4:
                await self._evolve_to_level_4()
            else:
                logger.warning(f"Nieznany poziom ewolucji: {next_level}")
                return
                
            # Aktualizacja poziomu ewolucji
            self.evolution_level = next_level
            logger.info(f"Zakończono ewolucję do poziomu {next_level}")
            
    async def _evolve_to_level_1(self):
        """Ewolucja do poziomu 1: Komunikacja rozszerzona"""
        logger.info("Ewolucja do poziomu 1: Dodawanie obsługi głosu")
        
        # Dodanie usług STT/TTS
        self.docker_manager.add_service(
            "stt",
            "Usługa rozpoznawania mowy (Vosk)",
            "Potrzebna do obsługi komunikacji głosowej"
        )
        
        self.docker_manager.add_service(
            "tts",
            "Usługa syntezy mowy (Mozilla TTS)",
            "Potrzebna do obsługi komunikacji głosowej"
        )
        
        # Aktualizacja możliwości
        self.capabilities["voice"] = True
        
        # Powiadomienie o zakończeniu ewolucji
        # ...
        
    async def _evolve_to_level_2(self):
        """Ewolucja do poziomu 2: Środowisko programistyczne"""
        logger.info("Ewolucja do poziomu 2: Dodawanie środowiska programistycznego")
        
        # Dodanie VS Code Server
        self.docker_manager.add_service(
            "code-server",
            "VS Code Server z rozszerzeniami",
            "Środowisko programistyczne do generowania i wykonywania kodu"
        )
        
        # Dodanie GitLab
        self.docker_manager.add_service(
            "gitlab",
            "GitLab CE (system kontroli wersji)",
            "System kontroli wersji do zarządzania kodem"
        )
        
        # Aktualizacja możliwości
        self.capabilities["code_generation"] = True
        self.capabilities["version_control"] = True
        
        # Powiadomienie o zakończeniu ewolucji
        # ...
        
    async def _evolve_to_level_3(self):
        """Ewolucja do poziomu 3: Zaawansowana automatyzacja"""
        # Implementacja ewolucji do poziomu 3
        # ...
        
    async def _evolve_to_level_4(self):
        """Ewolucja do poziomu 4: Pełna autonomia"""
        # Implementacja ewolucji do poziomu 4
        # ...